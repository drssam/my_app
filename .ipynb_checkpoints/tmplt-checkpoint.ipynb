{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e22c07-b944-4c72-829b-dcaae59b5f21",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Template Structure\n",
    "Each notebook should contain these sections:\n",
    "\n",
    "    1- Title & Project Overview\n",
    "        *Title of the notebook/project\n",
    "        *Short description of the dataset and project goals.\n",
    "        *Date & Author\n",
    "        *Define the problem statement.\n",
    "            -Problem statement: What are you trying to achieve?\n",
    "            -Key questions: Define questions you want to answer with the data\n",
    "\n",
    "    2- Imports & Configurations\n",
    "        *Import necessary Python libraries.\n",
    "        *Set visualization styles and global configurations.\n",
    "\n",
    "    3-Understanding the Data\n",
    "        *Load the dataset.\n",
    "        *Display dataset info, columns, and basic statistics.\n",
    "        \n",
    "    4- Data Cleaning & Preprocessing\n",
    "        *Handle missing values, duplicates, and incorrect data types.\n",
    "        *Convert dates and categorical data if needed.\n",
    "        *Ensure data consistency.\n",
    "        \n",
    "    5- Exploratory Data Analysis (EDA)\n",
    "        *Analyze distributions, correlations, and outliers.\n",
    "        *Generate histograms, scatterplots, and other visualizations.\n",
    "\n",
    "    6- Creative Analysis (NEW)\n",
    "        *Find new perspectives and insights from data.\n",
    "        *Engineer new features if useful.\n",
    "        *Compare groups or trends dynamically.\n",
    "\n",
    "    7- Visualization & Storytelling\n",
    "        *Present key findings visually.\n",
    "        *Highlight business or user-relevant insights.\n",
    "\n",
    "    8- Preliminary Model Building (Optional)\n",
    "        *If applicable, implement regression, clustering, or classification models.\n",
    "\n",
    "    9- Summary & Next Steps\n",
    "        *Key takeaways.\n",
    "        *Future improvements and questions to explore.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f56c0-1aae-4f24-9c63-d06c2f93a654",
   "metadata": {},
   "source": [
    "### Step 1: Title & Project Overview\n",
    "Now, let's start with Step 1: Title & Project Overview in your Jupyter Notebook.\n",
    "Fill in these details:\n",
    "\n",
    "    What is the title of this notebook?\n",
    "    How would you briefly describe the dataset and the goal of this project?\n",
    "    What key questions do you aim to answer using the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42442fb-64f2-4840-9d2a-99135da34ecb",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "    - Title: cars_data\n",
    "    - Brief Desciption: \n",
    "    - goal of this project: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbcdb0-8c87-46ea-afa4-912c5f174ace",
   "metadata": {},
   "source": [
    "## Step 2: Imports & Configurations\n",
    "In this step, we will:\n",
    "\n",
    "    âœ… Import all necessary Python libraries.\n",
    "    âœ… Set global configurations (e.g., display options, visualization styles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809462b-79a3-4b52-84a6-89e77ac6279f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "2ï¸âƒ£ Imports & Environment Setup\n",
    "Import necessary libraries\n",
    "\n",
    "Load helper functions (if needed)\n",
    "\n",
    "Set global visualization styles (e.g., Seaborn/Matplotlib themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f45794-832a-443e-add3-0601e7c0ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import astro\n",
    "import re\n",
    "from module import check_email\n",
    "\n",
    "import scipy.stats\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db302dfc-0f8e-4c1a-9d94-159af51abcb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "3ï¸âƒ£-1 Load & Inspect Data\n",
    "Now, we will:\n",
    "\n",
    "    âœ… Load the dataset into a Pandas DataFrame.\n",
    "    âœ… Get a high-level overview of its structure.\n",
    "    âœ… Identify any potential issues like missing values, incorrect data types, or inconsistencies.\n",
    "    âœ… Check first few rows\n",
    "    âœ… Check column names, data types, and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8a736-0b96-4c06-9eaf-8b56a06bc9c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Quick overview\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5512bf-17e7-4ab7-8866-3473a22360e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "3.2 Basic Exploration\n",
    "Now, letâ€™s check:\n",
    "\n",
    "    âœ… The number of missing values in each column.\n",
    "    âœ… Unique values in categorical columns.\n",
    "    âœ… Basic statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0672a-a3ad-47e4-a247-3aa2f7a997e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in '{col}':\")\n",
    "    print(df[col].unique())\n",
    "\n",
    "# Basic statistics for numerical columns\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b4a33-a0a4-4cc0-b6ed-5ac80499490f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##### Column Names May Need to Be More Accurate\n",
    "    ğŸ” 1. Column Names May Need to Be More Accurate\n",
    "        âœ… Youâ€™re right! Some column names could be improved for clarity.\n",
    "        For example:        \n",
    "        is_4wd â†’ has_4wd (to make it more readable as a boolean)        \n",
    "        odometer â†’ odometer_miles (so we know the unit)\n",
    "        date_posted â†’ listing_date (to make it clearer)\n",
    "        \n",
    "            ğŸ”¹ TIP:\n",
    "            Whenever working with datasets, check if column names are:\n",
    "            âœ”ï¸ Clear\n",
    "            âœ”ï¸ Self-explanatory\n",
    "            âœ”ï¸ Following a consistent naming style (e.g., snake_case or camelCase)\n",
    "        \n",
    "        ğŸ” 2. Data Types (dtypes) Need Fixing\n",
    "        âœ… Great observation! Some columns should have different data types.\n",
    "            Letâ€™s go through them one by one:            \n",
    "            model_year: Should be an integer (int), not a float. (There are no half-years for cars!)            \n",
    "            cylinders: Should be an integer (int), not a float. (We canâ€™t have 4.5 cylinders!)      \n",
    "            odometer: Should be an integer (int), not a float. (Odometer readings are whole numbers.)            \n",
    "            is_4wd: Should be boolean (True/False), instead of float (1.0 or NaN).            \n",
    "            date_posted: Should be a datetime type, instead of an object (string).\n",
    "        \n",
    "        ğŸ”¹ TIP:\n",
    "            Always check data types, because incorrect types can:        \n",
    "            Cause errors in calculations (e.g., \"2011\" stored as text instead of 2011 as a number)  \n",
    "            Affect performance (e.g., storing numbers as object is inefficient)        \n",
    "            Make it harder to use pandas functions\n",
    "        \n",
    "        ğŸ” 3. model Column Could Be Split into \"Make\" and \"Model\"\n",
    "            âœ… Yes! This is a great idea.\n",
    "            Right now, we have a mix of brands and models in one column.\n",
    "            For example, \"bmw x5\" â†’ We can split this into:\n",
    "            make: \"bmw\"        \n",
    "            model: \"x5\"\n",
    "            \n",
    "            This will allow us to:\n",
    "            âœ”ï¸ Group data by brand\n",
    "            âœ”ï¸ Compare models more easily\n",
    "            âœ”ï¸ Run deeper analyses\n",
    "        \n",
    "            ğŸ”¹ TIP:\n",
    "                Look for composite columns that contain more than one type of data.        \n",
    "                If separating them adds value â†’ Do it!  \n",
    "                If it doesnâ€™t improve analysis â†’ Keep it as-is.\n",
    "        \n",
    "        ğŸ” 4. Handling Missing Data\n",
    "            âœ… Your ideas are logical, but letâ€™s analyze them carefully.\n",
    "            ğŸŸ¢ model_year (Leave NaN)\n",
    "            âœ”ï¸ Correct!\n",
    "            Itâ€™s better to keep NaN instead of filling with random values.\n",
    "            If we replace missing years with something incorrect, we corrupt the dataset.\n",
    "        \n",
    "            ğŸŸ¢ odometer (Leave NaN)\n",
    "            âœ”ï¸ Correct!\n",
    "            We canâ€™t guess mileage, so itâ€™s better to leave it missing.\n",
    "        \n",
    "            ğŸŸ¡ is_4wd (Convert NaN to 0)\n",
    "            âš ï¸ Partially correct!\n",
    "            If NaN means the car does NOT have 4WD, then setting missing values to 0 makes sense.\n",
    "            However, if we donâ€™t know whether itâ€™s missing or truly 2WD, we should keep it NaN.\n",
    "\n",
    "        ğŸ”¹ TIP:\n",
    "            Before filling missing values, ask:\n",
    "            Does NaN mean \"unknown\"?            \n",
    "            Does NaN mean \"this feature doesnâ€™t apply\"?\n",
    "            Will replacing NaN with a default value create false data?\n",
    "\n",
    "    ğŸ” 5. Formatting the price Column\n",
    "        âœ… Good thinking!\n",
    "        In Python, we donâ€™t store price as a formatted string (e.g., $9,400.00).\n",
    "        Instead, we store it as an integer (int) or float (float) for calculations.\n",
    "        \n",
    "        We can format it later when displaying in Streamlit.\n",
    "\n",
    "        ğŸ”¹ TIP:\n",
    "            Numbers should stay as numbers.\n",
    "            Use formatting ({:,.2f}) when displaying, not in the dataset itself.\n",
    "            Never store numbers as strings unless absolutely necessary.\n",
    "\n",
    "    ğŸ” 6. Adding More Columns (Creative Section)\n",
    "        âœ… Yes! This is a great forward-thinking idea.\n",
    "        We can later create new columns based on existing data, such as:\n",
    "\n",
    "        Car Age = 2025 - model_year (if year is present)\n",
    "        Price per Mile = price / odometer (to see cost per mileage)\n",
    "        Listing Month = Extract month from date_posted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2d332-1a60-48bb-96ce-98f22eb30041",
   "metadata": {},
   "source": [
    "    ğŸ”¹ Step 1: Fix Data Types\n",
    "4ï¸âƒ£ Data Cleaning & Preprocessing\n",
    "\n",
    "    Handle missing values\n",
    "    Convert data types\n",
    "    Remove duplicates\n",
    "    Rename columns for clarity\n",
    "    Standardize formats (dates, text, categories)\n",
    "\n",
    "\n",
    "We'll convert:\n",
    "\n",
    "    model_year â†’ int (no decimals in years)\n",
    "    cylinders â†’ int\n",
    "    odometer â†’ int\n",
    "    is_4wd â†’ boolean (True/False)\n",
    "    date_posted â†’ datetime\n",
    "    Hereâ€™s the code and explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01946419-96a3-434c-a187-168cc2eb18d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Awesome! ğŸš€ Now, letâ€™s **start cleaning the data** based on what we just discussed.  \n",
    "\n",
    "We'll go **step by step**, explaining everything clearly.  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ”¹ Step 1: Fix Data Types**\n",
    "We'll convert:  \n",
    "- `model_year` â†’ `int` (no decimals in years)  \n",
    "- `cylinders` â†’ `int`  \n",
    "- `odometer` â†’ `int`  \n",
    "- `is_4wd` â†’ `boolean` (`True/False`)  \n",
    "- `date_posted` â†’ `datetime`  \n",
    "\n",
    "Hereâ€™s the code and explanation:  \n",
    "\n",
    "```python\n",
    "# Convert data types\n",
    "df['model_year'] = df['model_year'].astype('Int64')  # Uses Int64 to allow NaN values\n",
    "df['cylinders'] = df['cylinders'].astype('Int64')    # Same reason as above\n",
    "df['odometer'] = df['odometer'].astype('Int64')      # Convert to integer, allow NaN\n",
    "df['is_4wd'] = df['is_4wd'].fillna(0).astype(bool)   # Convert NaN to False, then to boolean\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])  # Convert to datetime format\n",
    "```\n",
    "ğŸ”¹ Step 1: Fix Data Types (Two Versions)\n",
    "âœ… Ordinary Code (Step-by-Step)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Convert data types one by one\n",
    "df['model_year'] = df['model_year'].astype('Int64')  # Allows NaN\n",
    "df['cylinders'] = df['cylinders'].astype('Int64')    \n",
    "df['odometer'] = df['odometer'].astype('Int64')      \n",
    "df['is_4wd'] = df['is_4wd'].fillna(0).astype(bool)  # Convert NaN to False, then to boolean\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])  # Convert to datetime\n",
    "âœ¨ Smart Code (One-Liner)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Dictionary method to apply conversions in one line\n",
    "df = df.astype({\n",
    "    'model_year': 'Int64', \n",
    "    'cylinders': 'Int64', \n",
    "    'odometer': 'Int64'\n",
    "}).assign(\n",
    "    is_4wd=df['is_4wd'].fillna(0).astype(bool), \n",
    "    date_posted=pd.to_datetime(df['date_posted'])\n",
    "\n",
    "    \n",
    "âœ… **Now, all data types should be correct!**  \n",
    "ğŸ‘‰ **Question:** Do you understand why we used `.astype('Int64')` instead of just `int`?  \n",
    "\n",
    "---\n",
    "\n",
    "âœ… Ordinary Code\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Split model into make and model columns\n",
    "df[['make', 'model']] = df['model'].str.split(' ', n=1, expand=True)\n",
    "âœ¨ Smart Code (One-Liner)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Uses assign to avoid modifying df directly\n",
    "df = df.assign(make=df['model'].str.split(' ', n=1).str[0], \n",
    "               model=df['model'].str.split(' ', n=1).str[1])\n",
    "Why is this smarter?\n",
    "âœ”ï¸ No need for expand=True\n",
    "âœ”ï¸ Directly extracts values using .str[]\n",
    "\n",
    "\n",
    "ğŸ”¹ Step 3: Rename Columns (Two Versions)\n",
    "âœ… Ordinary Code\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "df.rename(columns={\n",
    "    'odometer': 'odometer_miles',\n",
    "    'date_posted': 'listing_date',\n",
    "    'is_4wd': 'has_4wd'\n",
    "}, inplace=True)\n",
    "âœ¨ Smart Code (One-Liner)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "df = df.rename(columns={'odometer': 'odometer_miles', 'date_posted': 'listing_date', 'is_4wd': 'has_4wd'})\n",
    "âœ”ï¸ Same logic, but no inplace=True (safer in some cases)\n",
    "\n",
    "\n",
    "\n",
    "### **ğŸ”¹ Step 4: Final Check (Before Moving Forward)**\n",
    "At this stage, letâ€™s **re-check** everything:  \n",
    "\n",
    "```python\n",
    "print(df.info())  # Check data types\n",
    "print(df.head())  # Look at cleaned data\n",
    "```\n",
    "\n",
    "ğŸ‘‰ **Let me know:**  \n",
    "techniques like list comprehensions, apply with lambda functions, and vectorized operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97fb39-a072-4882-b46d-dba0b057b71f",
   "metadata": {},
   "source": [
    "Step 2: Handling Data Types and Formatting\n",
    "We will now clean the dataset by adjusting incorrect data types and formatting issues. Based on our observations, hereâ€™s what we need to do:\n",
    "\n",
    "Fixing Data Types:\n",
    "model_year: Convert to Int64 (pandas nullable integer type) because some values are missing.\n",
    "\n",
    "cylinders: Convert to Int64, as it represents discrete numbers.\n",
    "\n",
    "odometer: Convert to Int64 since odometer readings are always whole numbers.\n",
    "\n",
    "is_4wd: Convert to bool (0 for False, 1 for True).\n",
    "\n",
    "date_posted: Convert to datetime for easier time-based analysis.\n",
    "\n",
    "Formatting Adjustments:\n",
    "price: Format for better readability (e.g., thousands separator).\n",
    "\n",
    "Standard Code (Step-by-Step Approach)\n",
    "This is the more explicit approach:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Convert data types\n",
    "df['model_year'] = df['model_year'].astype('Int64')  # Nullable integer\n",
    "df['cylinders'] = df['cylinders'].astype('Int64')\n",
    "df['odometer'] = df['odometer'].astype('Int64')\n",
    "df['is_4wd'] = df['is_4wd'].fillna(0).astype(bool)  # Convert NaN to 0, then to boolean\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])  # Convert to datetime\n",
    "\n",
    "# Format price for readability\n",
    "df['price'] = df['price'].apply(lambda x: f\"{x:,}\")  # Adds comma separator\n",
    "Smart Code (Concise & Efficient Approach)\n",
    "\n",
    "This version reduces repetition and increases efficiency:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Define type conversions and apply in a loop\n",
    "convert_types = {\n",
    "    'model_year': 'Int64',\n",
    "    'cylinders': 'Int64',\n",
    "    'odometer': 'Int64',\n",
    "    'is_4wd': bool,\n",
    "    'date_posted': 'datetime64[ns]'\n",
    "}\n",
    "\n",
    "# Convert types\n",
    "df = df.astype(convert_types)\n",
    "df['is_4wd'] = df['is_4wd'].fillna(0).astype(bool)  # Special case for boolean conversion\n",
    "df['price'] = df['price'].map('{:,}'.format)  # Format prices efficiently\n",
    "Discussion:\n",
    "Why use .astype('Int64') instead of .astype(int)?\n",
    "\n",
    "int doesnâ€™t support missing values (NaN). Int64 (pandas nullable integer type) handles them properly.\n",
    "\n",
    "Why use map('{:,}'.format) instead of apply(lambda x: f\"{x:,}\")?\n",
    "\n",
    "map is optimized for simple functions like formatting strings, making it slightly faster than apply.\n",
    "\n",
    "Why is is_4wd handled separately?\n",
    "\n",
    "It needs fillna(0) before converting to bool, otherwise, NaNs would cause issues.\n",
    "\n",
    "Next Step\n",
    "Now that weâ€™ve corrected data types and formatting, we can move on. Let me know if you have any questions or if you'd like to test the changes with df.info() before proceeding! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef170b55-5d30-44b7-a578-9ca7ba0cd394",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **Step 3: Handling Missing Data**  \n",
    "\n",
    "Now, we will address missing values in the dataset. Letâ€™s analyze each column with missing data and decide on the best approach:\n",
    "\n",
    "#### **Columns with Missing Values:**  \n",
    "- `model_year`: Leave as `NaN` to avoid data corruption.  \n",
    "- `cylinders`: Leave as `NaN` since guessing could be inaccurate.  \n",
    "- `odometer`: Leave as `NaN` since imputation might introduce bias.  \n",
    "- `paint_color`: Missing values indicate unknown colors. We can replace with `\"unknown\"` for consistency.  \n",
    "- `is_4wd`: Already handled in Step 2 (`NaN` â†’ `0` â†’ `bool`).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Standard Code (Step-by-Step Approach)**  \n",
    "This method explicitly handles each column:\n",
    "\n",
    "```python\n",
    "# Fill missing values where appropriate\n",
    "df['paint_color'] = df['paint_color'].fillna('unknown')  # Replace NaN with 'unknown'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Smart Code (Concise & Efficient Approach)**  \n",
    "This approach uses a dictionary to apply multiple transformations at once:\n",
    "\n",
    "```python\n",
    "# Fill missing values using a dictionary\n",
    "df.fillna({'paint_color': 'unknown'}, inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Not Fill `model_year`, `cylinders`, and `odometer`?**  \n",
    "- **Imputation risks introducing errors.**  \n",
    "- **Leaving them as NaN ensures transparency and avoids assumptions.**  \n",
    "- **We can later analyze missing data patterns to decide if we should drop or fill them.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Step**  \n",
    "Now that weâ€™ve addressed missing values, we can move on to exploring and analyzing the data! ğŸš€ Let me know if you have any questions before we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a959259-d302-49b9-a820-cdc2112f5482",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Step 4: Exploratory Data Analysis (EDA)\n",
    "Now that weâ€™ve cleaned the data, letâ€™s explore it to understand distributions, relationships, and patterns. This will guide future transformations and visualizations.\n",
    "\n",
    "Key Questions for EDA\n",
    "What are the overall statistics of numerical data?\n",
    "\n",
    "Are there outliers that need attention?\n",
    "\n",
    "How are different categories distributed (e.g., fuel types, condition, transmission)?\n",
    "\n",
    "Are there correlations between variables?\n",
    "\n",
    "How is price distributed?\n",
    "\n",
    "Standard Code (Step-by-Step Approach)\n",
    "This method systematically explores the dataset.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# 1. Overview of numerical data\n",
    "print(df.describe())\n",
    "\n",
    "# 2. Checking categorical distributions\n",
    "print(df['fuel'].value_counts())\n",
    "print(df['condition'].value_counts())\n",
    "print(df['transmission'].value_counts())\n",
    "\n",
    "# 3. Correlation analysis (only numerical columns)\n",
    "print(df.corr())\n",
    "\n",
    "# 4. Price distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['price'], bins=50, kde=True)\n",
    "plt.title(\"Price Distribution\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "Smart Code (Concise & Efficient Approach)\n",
    "This approach runs multiple analyses at once.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Quick overview of numerical & categorical data\n",
    "display(df.describe(), df.select_dtypes(include='object').nunique())\n",
    "\n",
    "# Correlation analysis\n",
    "df.corr().style.background_gradient(cmap=\"coolwarm\")\n",
    "\n",
    "# Plotting price distribution\n",
    "sns.histplot(df['price'], bins=50, kde=True).set(title=\"Price Distribution\", xlabel=\"Price\")\n",
    "plt.show()\n",
    "Expected Insights from EDA\n",
    "âœ… Numerical Stats: Min/max values, means, standard deviations.\n",
    "âœ… Outliers: Extremely high prices, odometer values, or missing data.\n",
    "âœ… Categorical Distributions: Popular car conditions, common fuel types, transmission preferences.\n",
    "âœ… Correlations: Strong relationships (e.g., odometer vs. price or model_year vs. price).\n",
    "âœ… Price Distribution: Are there unusually expensive or cheap cars?\n",
    "\n",
    "Next Step\n",
    "Analyze the results and note any patterns, issues, or surprises.\n",
    "Let me know your observations, and Iâ€™ll help refine our analysis! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c23006-e252-4619-ab1e-48d5905c01ee",
   "metadata": {},
   "source": [
    "# Drop missing values (if necessary)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert column types\n",
    "df['date_column'] = pd.to_datetime(df['date_column'])\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Handling Missing Values â€“ Step by Step\n",
    "1ï¸âƒ£ model_year (3,619 missing)\n",
    "Option 1 (Best for Accuracy): Keep NaN values.\n",
    "\n",
    "This prevents introducing incorrect data.\n",
    "\n",
    "Option 2 (Fill with median per make/model):\n",
    "\n",
    "Use median model_year for each car make & model.\n",
    "\n",
    "Example: Fill missing model_year of a Ford F-150 with the median model_year of all Ford F-150s.\n",
    "\n",
    "Option 3 (Fill with overall median):\n",
    "\n",
    "Less accurate but a quick fix.\n",
    "\n",
    "2ï¸âƒ£ cylinders (5,260 missing)\n",
    "Option 1 (Best for Accuracy): Use median per car type.\n",
    "\n",
    "SUVs & Trucks usually have 6-8 cylinders, while sedans have 4 cylinders.\n",
    "\n",
    "Option 2: Use mode (most common value for each model).\n",
    "\n",
    "Option 3: Keep NaN if unsure.\n",
    "\n",
    "3ï¸âƒ£ odometer_miles (7,892 missing)\n",
    "Option 1: Predict using model_year (newer = lower mileage).\n",
    "\n",
    "Option 2: Use median per model & model_year.\n",
    "\n",
    "Option 3: Leave NaN.\n",
    "\n",
    "4ï¸âƒ£ paint_color (9,267 missing)\n",
    "This is not critical for price prediction.\n",
    "\n",
    "Can either keep missing or fill with \"unknown\".\n",
    "\n",
    "Letâ€™s Code Two Versions:\n",
    "1ï¸âƒ£ Ordinary version (clear & readable)\n",
    "2ï¸âƒ£ Smart version (short & efficient)\n",
    "\n",
    "ğŸ“Œ Ordinary Version (Step-by-Step)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Fill 'model_year' using median per make/model\n",
    "df['model_year'] = df.groupby(['make', 'model'])['model_year'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill 'cylinders' using median per type\n",
    "df['cylinders'] = df.groupby('type')['cylinders'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill 'odometer_miles' using median per model/model_year\n",
    "df['odometer_miles'] = df.groupby(['model', 'model_year'])['odometer_miles'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill 'paint_color' with 'unknown'\n",
    "df['paint_color'].fillna('unknown', inplace=True)\n",
    "ğŸ“Œ Smart Version (Short & Efficient)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "fill_medians = ['model_year', 'cylinders', 'odometer_miles']\n",
    "for col in fill_medians:\n",
    "    df[col] = df.groupby(df[col].dropna().index)[col].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df['paint_color'].fillna('unknown', inplace=True)\n",
    "This reduces 4 lines to 2 lines! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b495179-3056-465e-bc84-1ddde6a3b283",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "No, the syntax `df['fuel', 'condition', 'transmission'].value_counts()` **wonâ€™t work** because Pandas does not allow selecting multiple columns in that way for `value_counts()`. However, here are **three** better ways to achieve what you want:\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Option 1: Looping Through Columns (Standard & Clear)**\n",
    "This method is explicit and easy to read.\n",
    "\n",
    "```python\n",
    "for col in ['fuel', 'condition', 'transmission']:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    print(df[col].value_counts())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Option 2: Using `.apply()` for a More Compact Approach**\n",
    "This applies `value_counts()` to each column at once.\n",
    "\n",
    "```python\n",
    "df[['fuel', 'condition', 'transmission']].apply(pd.Series.value_counts)\n",
    "```\n",
    "\n",
    "â© **This outputs a DataFrame** where each column's unique values are counted side by side.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Option 3: Using `melt()` + `value_counts()` for a Super Compact Pivot**\n",
    "This transforms the dataset before applying `value_counts()`.\n",
    "\n",
    "```python\n",
    "df.melt(value_vars=['fuel', 'condition', 'transmission']).value_counts()\n",
    "```\n",
    "\n",
    "â© **This method is useful when you want all category counts in a single list.** Itâ€™s a powerful trick!\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- âŒ `df['fuel', 'condition', 'transmission'].value_counts()` **is incorrect.**\n",
    "- âœ… Use **Option 1 (loop)** for readability.\n",
    "- âœ… Use **Option 2 (`apply()`)** for compact, structured output.\n",
    "- âœ… Use **Option 3 (`melt()`)** for a unique summary.\n",
    "\n",
    "Which one do you prefer? ğŸš€\n",
    "\n",
    "Fix:\n",
    "We need to select only numeric columns before calling .corr().\n",
    "\n",
    "Corrected Code:\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Select only numeric columns for correlation analysis\n",
    "numeric_df = df.select_dtypes(include=['number'])  \n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Display correlation with a heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "Alternative (One-Liner Smart Code)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, cmap='coolwarm', fmt=\".2f\").set(title=\"Correlation Matrix\")\n",
    "plt.show()\n",
    "Next Steps:\n",
    "Check the heatmap:\n",
    "\n",
    "Which variables are strongly correlated?\n",
    "\n",
    "Do any correlations seem unexpected or illogical?\n",
    "\n",
    "Decide if further transformations are needed:\n",
    "\n",
    "Do we need to engineer new features based on correlations?\n",
    "\n",
    "Should we drop any redundant columns?\n",
    "\n",
    "Let me know what you observe! ğŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3991358-885c-415a-be8e-99fa04b04eb8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **Observations from the Correlation Matrix**\n",
    "1. **Price vs. Model Year** (`0.43`):  \n",
    "   - Newer cars tend to have **higher prices** (positive correlation).  \n",
    "   - This makes sense since **newer models are usually more expensive**.  \n",
    "\n",
    "2. **Price vs. Odometer** (`-0.42`):  \n",
    "   - Higher mileage cars tend to be **cheaper** (negative correlation).  \n",
    "   - This is logicalâ€”**more used cars depreciate in value**.  \n",
    "\n",
    "3. **Cylinders vs. Price** (`0.30`):  \n",
    "   - Vehicles with more cylinders **tend to be more expensive**.  \n",
    "   - Likely because **higher-cylinder cars are often larger & more powerful** (trucks, SUVs, sports cars).  \n",
    "\n",
    "4. **Model Year vs. Odometer** (`-0.47`):  \n",
    "   - Newer cars have **lower mileage**, which is expected.  \n",
    "\n",
    "5. **Days Listed has very weak correlations (~0.00 to ~0.005)**  \n",
    "   - This suggests that **days listed does not strongly depend on other factors**.  \n",
    "   - We might need **more features** to explain listing duration (e.g., location, demand, price competitiveness).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Whatâ€™s Next?**\n",
    "**Do you want to:**\n",
    "1. **Visualize these relationships?** (scatter plots, histograms, or box plots)\n",
    "2. **Check for outliers?** (extremely high or low values in price, odometer, etc.)\n",
    "3. **Investigate more feature engineering ideas?**  \n",
    "\n",
    "Your choice! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327f797-4a6f-4f74-a5ec-990f285d2cdc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Got it! I'll guide you with the best approach so you develop a strong foundation in data science. Let's continue refining our analysis logically, ensuring you build the right habits and ways of thinking.\n",
    "\n",
    "Next, let's interpret the correlation matrix properly:\n",
    "\n",
    "Understanding strong correlations:\n",
    "\n",
    "price and model_year (0.43) â†’ Newer cars tend to be more expensive.\n",
    "\n",
    "price and cylinders (0.30) â†’ More cylinders may mean a more powerful (and pricier) vehicle.\n",
    "\n",
    "price and odometer_miles (-0.42) â†’ Higher mileage cars are generally cheaper.\n",
    "\n",
    "Weak or no correlation:\n",
    "\n",
    "days_listed has near-zero correlation with price and most other factors, meaning listing duration doesnâ€™t seem to depend much on the vehicle attributes.\n",
    "\n",
    "Before deciding what to do next, would you like to visualize these correlations using a heatmap? It will help us better interpret the relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d41065-c1ca-4aad-a214-c8f2ca3d4f55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great thinking! Since the correlation matrix didnâ€™t reveal new insights, we need to switch our approach and analyze the data differently.\n",
    "\n",
    "Options for Next Steps:\n",
    "1ï¸âƒ£ Explore Relationships with Visualizations\n",
    "Scatter plots: Show relationships between price and other numerical features.\n",
    "\n",
    "Box plots: Compare price across categories (e.g., fuel type, transmission).\n",
    "\n",
    "2ï¸âƒ£ Feature Engineering (Creating New Features)\n",
    "Price per mile: price / odometer_miles\n",
    "\n",
    "Car age: 2025 - model_year (to get a clearer time-related effect)\n",
    "\n",
    "High mileage flag: Mark cars with very high mileage (e.g., over 150,000 miles).\n",
    "\n",
    "3ï¸âƒ£ Statistical Tests for Categorical Features\n",
    "Find if transmission, fuel type, or vehicle type significantly affect price.\n",
    "\n",
    "Use groupby() to calculate average prices for different categories.\n",
    "\n",
    "What Would You Like to Do Next?\n",
    "Visualizations? (Scatter plots, box plots, histograms)\n",
    "\n",
    "Feature Engineering? (Create new insights)\n",
    "\n",
    "Statistical Testing? (Analyze price differences between categories)\n",
    "\n",
    "Tell me which direction excites you the most, and weâ€™ll dive right in! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37d61e-7824-4aaa-8ac7-33b008cc11c6",
   "metadata": {},
   "source": [
    "Great! The best strategy for a data scientist is to **first create new features (Option 2) and then test their impact (Option 3)**. So let's start with **Feature Engineering** and then move to **Statistical Testing**!  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Feature Engineering (Creating New Insights)**  \n",
    "We'll create new columns to give us **deeper insights** into the data. Hereâ€™s what weâ€™ll add:  \n",
    "\n",
    "1ï¸âƒ£ **Car Age**: Instead of using `model_year`, weâ€™ll calculate how old the car is.  \n",
    "   - Formula: `car_age = 2025 - model_year`  \n",
    "   - New column: `car_age`  \n",
    "\n",
    "2ï¸âƒ£ **Price per Mile**: Price divided by odometer miles to measure value.  \n",
    "   - Formula: `price_per_mile = price / odometer_miles`  \n",
    "   - New column: `price_per_mile`  \n",
    "\n",
    "3ï¸âƒ£ **High Mileage Flag**: A column that marks high-mileage cars (above 150,000 miles).  \n",
    "   - If odometer > 150,000 â†’ **1 (High mileage)**  \n",
    "   - Otherwise â†’ **0 (Normal mileage)**  \n",
    "   - New column: `high_mileage` (Boolean 0/1)  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Statistical Testing (Checking Category Effects on Price)**\n",
    "After feature engineering, weâ€™ll check if some **categories significantly affect price**.  \n",
    "- **Does fuel type affect price?** (group by fuel type and compare prices)  \n",
    "- **Does transmission affect price?**  \n",
    "- **Do SUVs cost more than sedans on average?**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Do you agree with this plan?** If yes, Iâ€™ll write the code for Step 1 (Feature Engineering). ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9003ed4-a0f9-4e77-8646-85974697aa46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Awesome! Let's start with **Feature Engineering** ğŸš€  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Feature Engineering (Adding New Insights)**  \n",
    "\n",
    "Hereâ€™s the **step-by-step breakdown**:  \n",
    "1ï¸âƒ£ **Car Age** â†’ Subtract `model_year` from 2025.  \n",
    "2ï¸âƒ£ **Price per Mile** â†’ Divide price by odometer miles (handle division by zero).  \n",
    "3ï¸âƒ£ **High Mileage Flag** â†’ Mark cars with **odometer > 150,000 miles** as **1 (High Mileage), else 0**.  \n",
    "\n",
    "Iâ€™ll provide **two versions** of the code:  \n",
    "- **Ordinary version** (Easy to understand)  \n",
    "- **Smart version** (Shorter, efficient, Pythonic)  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸš€ Ordinary Version (Step-by-Step for Clarity)**\n",
    "```python\n",
    "# 1. Create Car Age column\n",
    "df['car_age'] = 2025 - df['model_year']\n",
    "\n",
    "# 2. Create Price per Mile column (handling division by zero)\n",
    "df['price_per_mile'] = df['price'] / df['odometer_miles']\n",
    "df['price_per_mile'].replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities with NaN\n",
    "\n",
    "# 3. Create High Mileage Flag (1 if > 150,000 miles, else 0)\n",
    "df['high_mileage'] = df['odometer_miles'].apply(lambda x: 1 if x > 150000 else 0)\n",
    "\n",
    "# Display the first few rows with new features\n",
    "df.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ’¡ Smart Version (Pythonic, Short & Efficient)**\n",
    "```python\n",
    "# Add new features efficiently in one go\n",
    "df = df.assign(\n",
    "    car_age = 2025 - df['model_year'],\n",
    "    price_per_mile = lambda x: x['price'] / x['odometer_miles'],\n",
    "    high_mileage = lambda x: (x['odometer_miles'] > 150000).astype(int)\n",
    ")\n",
    "\n",
    "# Handle division by zero\n",
    "df['price_per_mile'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df.head()  # Show result\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ¯ Next Step**\n",
    "Once this is done, weâ€™ll move to **Step 2: Statistical Testing** to check which features impact price.   \n",
    "\n",
    "ğŸš€ **Run the code and let me know if you have any questions before we continue!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd2bc4-67f4-4366-859f-c4519de954c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great! The best strategy for a data scientist is to **first create new features (Option 2) and then test their impact (Option 3)**. So let's start with **Feature Engineering** and then move to **Statistical Testing**!  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Feature Engineering (Creating New Insights)**  \n",
    "We'll create new columns to give us **deeper insights** into the data. Hereâ€™s what weâ€™ll add:  \n",
    "\n",
    "1ï¸âƒ£ **Car Age**: Instead of using `model_year`, weâ€™ll calculate how old the car is.  \n",
    "   - Formula: `car_age = 2025 - model_year`  \n",
    "   - New column: `car_age`  \n",
    "\n",
    "2ï¸âƒ£ **Price per Mile**: Price divided by odometer miles to measure value.  \n",
    "   - Formula: `price_per_mile = price / odometer_miles`  \n",
    "   - New column: `price_per_mile`  \n",
    "\n",
    "3ï¸âƒ£ **High Mileage Flag**: A column that marks high-mileage cars (above 150,000 miles).  \n",
    "   - If odometer > 150,000 â†’ **1 (High mileage)**  \n",
    "   - Otherwise â†’ **0 (Normal mileage)**  \n",
    "   - New column: `high_mileage` (Boolean 0/1)  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Statistical Testing (Checking Category Effects on Price)**\n",
    "After feature engineering, weâ€™ll check if some **categories significantly affect price**.  \n",
    "- **Does fuel type affect price?** (group by fuel type and compare prices)  \n",
    "- **Does transmission affect price?**  \n",
    "- **Do SUVs cost more than sedans on average?**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Do you agree with this plan?** If yes, Iâ€™ll write the code for Step 1 (Feature Engineering). ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b59222-729c-478c-a268-1d970f15013a",
   "metadata": {},
   "source": [
    "Awesome! Let's start with **Feature Engineering** ğŸš€  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Feature Engineering (Adding New Insights)**  \n",
    "\n",
    "Hereâ€™s the **step-by-step breakdown**:  \n",
    "1ï¸âƒ£ **Car Age** â†’ Subtract `model_year` from 2025.  \n",
    "2ï¸âƒ£ **Price per Mile** â†’ Divide price by odometer miles (handle division by zero).  \n",
    "3ï¸âƒ£ **High Mileage Flag** â†’ Mark cars with **odometer > 150,000 miles** as **1 (High Mileage), else 0**.  \n",
    "\n",
    "Iâ€™ll provide **two versions** of the code:  \n",
    "- **Ordinary version** (Easy to understand)  \n",
    "- **Smart version** (Shorter, efficient, Pythonic)  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸš€ Ordinary Version (Step-by-Step for Clarity)**\n",
    "```python\n",
    "# 1. Create Car Age column\n",
    "df['car_age'] = 2025 - df['model_year']\n",
    "\n",
    "# 2. Create Price per Mile column (handling division by zero)\n",
    "df['price_per_mile'] = df['price'] / df['odometer_miles']\n",
    "df['price_per_mile'].replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinities with NaN\n",
    "\n",
    "# 3. Create High Mileage Flag (1 if > 150,000 miles, else 0)\n",
    "df['high_mileage'] = df['odometer_miles'].apply(lambda x: 1 if x > 150000 else 0)\n",
    "\n",
    "# Display the first few rows with new features\n",
    "df.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ’¡ Smart Version (Pythonic, Short & Efficient)**\n",
    "```python\n",
    "# Add new features efficiently in one go\n",
    "df = df.assign(\n",
    "    car_age = 2025 - df['model_year'],\n",
    "    price_per_mile = lambda x: x['price'] / x['odometer_miles'],\n",
    "    high_mileage = lambda x: (x['odometer_miles'] > 150000).astype(int)\n",
    ")\n",
    "\n",
    "# Handle division by zero\n",
    "df['price_per_mile'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df.head()  # Show result\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ¯ Next Step**\n",
    "Once this is done, weâ€™ll move to **Step 2: Statistical Testing** to check which features impact price.   \n",
    "\n",
    "Yes, this is a **FutureWarning**, meaning it's not breaking your code, but in future versions of Pandas (3.0+), the behavior will change.  \n",
    "\n",
    "### **Why does this happen?**\n",
    "- Pandas is telling you that using `inplace=True` inside a chained assignment might not work reliably in the future.  \n",
    "- This happens because `df['price_per_mile']` is being modified **directly on a copy** rather than the original DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **âœ… Fix: Update the Column Without `inplace=True`**\n",
    "```python\n",
    "df['price_per_mile'] = df['price_per_mile'].replace([np.inf, -np.inf], np.nan)\n",
    "```\n",
    "ğŸ’¡ **Key Fix:** Just remove `inplace=True`, and the warning disappears while ensuring your column updates correctly.\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸš€ Alternative (Even Cleaner)**\n",
    "Modify the whole feature generation in **one line**:\n",
    "```python\n",
    "df = df.assign(\n",
    "    car_age = 2025 - df['model_year'],\n",
    "    price_per_mile = lambda x: x['price'].div(x['odometer_miles']).replace([np.inf, -np.inf], np.nan),\n",
    "    high_mileage = lambda x: (x['odometer_miles'] > 150000).astype(int)\n",
    ")\n",
    "```\n",
    "This prevents chained assignment issues and makes the code more efficient. ğŸš€\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ”¹ **Try this fix and let me know if you get any other warnings!** ğŸ˜ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214c180-e2d5-4d40-9ed2-a5284ed959af",
   "metadata": {},
   "source": [
    "ğŸ”¹ Best External Datasets to Enrich Our Analysis\n",
    "1ï¸âƒ£ Inflation & Economic Data\n",
    "Why? Car prices depend on inflation, interest rates, and overall economic trends.\n",
    "\n",
    "Dataset: CPI (Consumer Price Index) & Inflation Rate\n",
    "\n",
    "Source: U.S. Bureau of Labor Statistics (BLS)\n",
    "\n",
    "How to Use? Adjust historical car prices for inflation to compare prices over time accurately.\n",
    "\n",
    "2ï¸âƒ£ Fuel Prices Over Time\n",
    "Why? Fuel costs impact vehicle demand and resale values.\n",
    "\n",
    "Dataset: Gasoline & Diesel Prices by Year/Region\n",
    "\n",
    "Source: U.S. Energy Information Administration (EIA)\n",
    "\n",
    "How to Use? Compare fuel-efficient vs. gas-guzzling cars and see how fuel costs influence prices.\n",
    "\n",
    "3ï¸âƒ£ Vehicle Reliability & Repair Cost Data\n",
    "Why? Some brands/models depreciate faster due to high maintenance costs.\n",
    "\n",
    "Dataset: Repair Costs & Reliability Ratings by Make/Model\n",
    "\n",
    "Source: Consumer Reports & CarMD\n",
    "\n",
    "How to Use? See if more reliable cars retain their value better.\n",
    "\n",
    "4ï¸âƒ£ Population & Income Data\n",
    "Why? Car prices vary by location based on demand and affordability.\n",
    "\n",
    "Dataset: Median Household Income & Population Density\n",
    "\n",
    "Source: U.S. Census Bureau\n",
    "\n",
    "How to Use? See if high-income areas have higher-priced used cars.\n",
    "\n",
    "5ï¸âƒ£ Used Car Market Trends\n",
    "Why? External market trends affect resale prices.\n",
    "\n",
    "Dataset: Vehicle Sales & Market Trends\n",
    "\n",
    "Source: Edmunds & Kelley Blue Book (KBB)\n",
    "\n",
    "How to Use? Compare our datasetâ€™s price trends to national trends.\n",
    "\n",
    "ğŸ”¹ Which One Should We Add First?\n",
    "ğŸ“Œ Best Option: Fuel Prices + Inflation Data\n",
    "\n",
    "They directly impact car prices and are easy to integrate.\n",
    "\n",
    "They help us analyze real price changes over time.\n",
    "\n",
    "Would you like to fetch one of these datasets now and integrate it? ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50d9d1-9d0f-45c7-9a6a-c00f58c0247c",
   "metadata": {},
   "source": [
    "Haha, youâ€™re thinking like a **strategic analyst** now! Youâ€™re rightâ€”adding datasets that highlight **negative factors** (inflation, high gas prices, repair costs) could make the cars look less attractive.  \n",
    "\n",
    "So letâ€™s **flip the perspective** and bring in **data that makes the cars more appealing to buyers!** ğŸš€  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ”¹ External Datasets That Could Help SELL These Cars Better**  \n",
    "\n",
    "#### **1ï¸âƒ£ Car Popularity & Demand ğŸ“ˆ**  \n",
    "**Why?** Some models are in high demand, meaning they **hold their value better** and are **easier to sell.**  \n",
    "- **Dataset:** Most-Searched & Best-Selling Used Cars  \n",
    "- **Source:** [Edmunds](https://www.edmunds.com/) or [AutoTrader](https://www.autotrader.com/)  \n",
    "- **How to Use?** If a car in our dataset is a **top seller**, highlight that fact!  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2ï¸âƒ£ Safety Ratings & Crash Test Scores ğŸš—ğŸ’¥**  \n",
    "**Why?** Safer cars are **more desirable** and command **higher resale prices.**  \n",
    "- **Dataset:** Crash Test Ratings by Model  \n",
    "- **Source:** [NHTSA (National Highway Traffic Safety Administration)](https://www.nhtsa.gov/)  \n",
    "- **How to Use?** Highlight cars with **5-star safety ratings** to attract families & safety-conscious buyers.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3ï¸âƒ£ Fuel Efficiency (MPG) & Hybrid Models â›½ğŸ”‹**  \n",
    "**Why?** People **love saving on gas**â€”fuel-efficient cars are a selling point!  \n",
    "- **Dataset:** Fuel Efficiency Ratings (MPG) by Model  \n",
    "- **Source:** [EPA Fuel Economy Database](https://www.fueleconomy.gov/)  \n",
    "- **How to Use?** Promote fuel-efficient models as **cost-saving choices.**  \n",
    "\n",
    "---\n",
    "\n",
    "#### **4ï¸âƒ£ Car Awards & Recognitions ğŸ†**  \n",
    "**Why?** Award-winning cars **hold their value better** and are easier to sell.  \n",
    "- **Dataset:** \"Best Used Cars to Buy\" Awards  \n",
    "- **Source:** [Consumer Reports](https://www.consumerreports.org/) or [J.D. Power](https://www.jdpower.com/)  \n",
    "- **How to Use?** Mention if a car was ranked **\"Best Midsize Sedan\"** in its category!  \n",
    "\n",
    "---\n",
    "\n",
    "#### **5ï¸âƒ£ Insurance Cost Data ğŸ’°**  \n",
    "**Why?** Lower insurance costs make a car **more affordable** in the long run.  \n",
    "- **Dataset:** Average Insurance Cost by Model  \n",
    "- **Source:** [Insurance Institute for Highway Safety (IIHS)](https://www.iihs.org/)  \n",
    "- **How to Use?** Highlight **low-insurance-cost cars** for budget-conscious buyers.  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ”¹ Which Dataset Should We Add First?**  \n",
    "ğŸ“Œ **Best Option:** **Fuel Efficiency + Safety Ratings**  \n",
    "- These are **HUGE selling points** and **directly impact buyer decisions.**  \n",
    "- We can highlight **cars that save money on gas** and are **super safe to drive.**  \n",
    "\n",
    "ğŸ”¥ **Would you like to fetch a fuel efficiency or safety rating dataset to integrate with our analysis?** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8d6e3-7e7b-476a-b35f-dffe0f48c651",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great choice! ğŸš€ Weâ€™ll integrate **fuel efficiency (MPG) and safety ratings** into our dataset step by step. Hereâ€™s how:\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Find Public Datasets**  \n",
    "We need two sources:  \n",
    "1ï¸âƒ£ **Fuel Economy (MPG)**: [EPA Fuel Economy Database](https://www.fueleconomy.gov/)  \n",
    "2ï¸âƒ£ **Safety Ratings**: [NHTSA Crash Test Ratings](https://www.nhtsa.gov/)  \n",
    "\n",
    "ğŸ‘‰ These sources provide data on **MPG, crash test scores, and safety features** for different car models.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Download & Load Data into Pandas**  \n",
    "ğŸ”¹ **Option 1: Direct Download**  \n",
    "- Go to the [EPA Fuel Economy Database](https://www.fueleconomy.gov/feg/download.shtml) and download the latest CSV.  \n",
    "- Go to [NHTSA Safety Ratings](https://www.nhtsa.gov/ratings) and grab crash test results.  \n",
    "\n",
    "ğŸ”¹ **Option 2: Use an API**  \n",
    "- The **EPA** and **NHTSA** offer **APIs** to pull data dynamically.  \n",
    "- Example: We can fetch safety ratings via the NHTSA API.  \n",
    "\n",
    "Would you like to **manually download the data** or should we **fetch it using an API**? ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89200e4-e963-40e4-bbd7-c6a3a70bf903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **ğŸ”¹ Creative Analysis Plan for Our Own Dataset**  \n",
    "\n",
    "Since we want to explore new insights before integrating the external dataset, letâ€™s break this into **three steps**:  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ” 1. Find New Perspectives & Insights**  \n",
    "We can explore relationships between different variables to uncover trends. Here are some useful analyses:  \n",
    "\n",
    "- **Price vs. Car Age:**  \n",
    "  - Do older cars always sell for less, or are there exceptions (e.g., classic cars)?  \n",
    "- **Price vs. Odometer:**  \n",
    "  - Do high-mileage cars always have lower prices? Any anomalies?  \n",
    "- **Condition vs. Price:**  \n",
    "  - How much does \"like new\" increase the price compared to \"good\" or \"fair\"?  \n",
    "- **Transmission vs. Price:**  \n",
    "  - Are manual cars cheaper than automatics?  \n",
    "- **4WD vs. Price:**  \n",
    "  - Does having 4WD significantly affect the price?  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ›  2. Engineer New Features**  \n",
    "We could add **derived features** to enhance our dataset:  \n",
    "\n",
    "âœ… **Depreciation Rate:**  \n",
    "   - How much does a car lose value per year on average?  \n",
    "   ```python\n",
    "   df['depreciation_rate'] = df['price'] / df['car_age']\n",
    "   ```  \n",
    "âœ… **Price Per Cylinder:**  \n",
    "   - Are V8 engines always more expensive than 4-cylinder engines?  \n",
    "   ```python\n",
    "   df['price_per_cylinder'] = df['price'] / df['cylinders']\n",
    "   ```  \n",
    "âœ… **Luxury vs. Economy Brand (New Column):**  \n",
    "   - Are BMWs, Audis, and Mercedes priced significantly higher than Toyotas and Fords?  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“Š 3. Compare Groups & Trends Dynamically**  \n",
    "We should:  \n",
    "\n",
    "- **Analyze price differences by fuel type (gas vs. electric vs. hybrid).**  \n",
    "- **See if certain car types (SUV, sedan, pickup) hold value better over time.**  \n",
    "- **Investigate whether listing duration (`days_listed`) correlates with price.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“Œ Action Step**  \n",
    "ğŸ‘‰ First, let's check some relationships before we add the external dataset. Try running:  \n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Price vs. Car Age\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x=df['car_age'], y=df['price'], alpha=0.5)\n",
    "plt.title('Car Age vs. Price')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This will help **visualize depreciation**. If this looks interesting, we can run more comparisons and prepare for merging the external dataset. ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a3f70-bbd0-4091-a1e4-ffe0b5203c22",
   "metadata": {},
   "source": [
    "Good question! Let's break it down step by step.  \n",
    "\n",
    "### **âœ… First Line of Code (Column Names)**\n",
    "```python\n",
    "all_cars_models.columns = all_cars_models.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"(\", \"\").str.replace(\")\", \"\")\n",
    "```\n",
    "âœ” Converts column names to lowercase  \n",
    "âœ” Replaces spaces with underscores  \n",
    "âœ” Removes parentheses  \n",
    "\n",
    "âœ… **Keep this line**â€”it's useful for making column names consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### **âœ… Second Line of Code (Lowercasing Data)**\n",
    "```python\n",
    "all_cars_models = all_cars_models.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "```\n",
    "âœ” Converts all string values in the dataset to lowercase  \n",
    "âœ” Does **not** remove extra spaces  \n",
    "\n",
    "âœ… **Keep this line**, but **replace it with the next version** to ensure no extra spaces remain.\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸš€ Improved Version (Lowercasing + Stripping Extra Spaces)**\n",
    "```python\n",
    "all_cars_models = all_cars_models.apply(lambda x: x.str.lower().str.strip() if x.dtype == \"object\" else x)\n",
    "```\n",
    "âœ” Converts all text to lowercase  \n",
    "âœ” **Removes leading/trailing spaces** (avoids issues with merging datasets)  \n",
    "\n",
    "âœ… **Yes, use this version instead of the second line!** It ensures cleaner data.\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ”¥ Final Code (Best Practice)**\n",
    "```python\n",
    "# Clean column names\n",
    "all_cars_models.columns = all_cars_models.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"(\", \"\").str.replace(\")\", \"\")\n",
    "\n",
    "# Convert all text to lowercase and strip spaces\n",
    "all_cars_models = all_cars_models.apply(lambda x: x.str.lower().str.strip() if x.dtype == \"object\" else x)\n",
    "```\n",
    "This will **standardize your dataset**, making merges and comparisons much smoother. ğŸš€\n",
    "\n",
    "Let me know if you need further refinements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555143db-e5c1-4137-9140-5eb6268d4caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc148c2-014c-432d-a975-f92760919861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa53c4-7f29-4b66-bf1b-4a949523955a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206835a4-5a4c-4cd6-8e2f-b9465b76607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1b7a6-5e48-4a44-8e8b-847a86de7f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f49b6a-2d94-4d08-89ff-fcd588bf3bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fa6ab-c375-41cc-bda6-19d831abc223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef3716-3d48-448f-b29f-d4835c610913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd42fb-8328-413e-81a4-e0f23fdc3f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418068c3-346f-42cb-a4a3-05ed5ec1512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44c065-0eda-403c-93b0-3d92de01ae04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581ef13-f6cb-4771-902b-61bea08e9b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4175fb-868b-4391-8e6c-a3233af34b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05870ae0-d949-449b-a46f-e52ebd8d6e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742287dd-33c3-47d5-bf42-803749195cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1b1a0-2485-4fa1-8b3c-18466c017053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1634668b-ff3e-4c57-87a6-d0aa892ab2c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efd1c935-1357-4851-9b66-8fb7ae0d58f3",
   "metadata": {},
   "source": [
    "6ï¸âƒ£ ğŸš€ Creative Analysis Section (Unique Insights)\n",
    "ğŸ’¡ This section is where you go beyond basic EDA!\n",
    "\n",
    "Think outside the box: What additional insights can be extracted?\n",
    "\n",
    "Can you create new features?\n",
    "\n",
    "Are there hidden patterns in the data?\n",
    "Examples:\n",
    "\n",
    "Creating a new categorical feature\n",
    "\n",
    "Identifying outliers using advanced methods\n",
    "\n",
    "Finding hidden trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc09286-e7a4-4161-af89-2f47da681e76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new feature (e.g., time since an event)\n",
    "df['days_since_event'] = (pd.to_datetime(\"today\") - df['date_column']).dt.days\n",
    "\n",
    "# Flag outliers using the IQR method\n",
    "Q1 = df['numeric_column'].quantile(0.25)\n",
    "Q3 = df['numeric_column'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df['outlier_flag'] = ((df['numeric_column'] < (Q1 - 1.5 * IQR)) | (df['numeric_column'] > (Q3 + 1.5 * IQR)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eedcfd-09c1-400a-9c14-b25fcee6b207",
   "metadata": {},
   "source": [
    "7ï¸âƒ£ Data Visualization\n",
    "Use Plotly, Seaborn, Altair, or other visualization libraries\n",
    "\n",
    "Create interactive charts when needed\n",
    "\n",
    "Always include labels & titles for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a911005079269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter plot\n",
    "fig = px.scatter(df, x=\"feature_x\", y=\"feature_y\", color=\"category_column\", title=\"Scatter Plot Example\")\n",
    "fig.show()\n",
    "\n",
    "# Boxplot for outlier detection\n",
    "sns.boxplot(x=df[\"numeric_column\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17008b2e-099e-4b62-9859-71548f95783b",
   "metadata": {},
   "source": [
    "8ï¸âƒ£ Key Findings & Conclusions\n",
    "Summarize the most important insights\n",
    "\n",
    "Provide interpretations of the data\n",
    "\n",
    "Identify limitations and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c94cd-b1b0-456b-8f5b-87df05fe448e",
   "metadata": {},
   "source": [
    "9ï¸âƒ£ Next Steps / Actionable Recommendations\n",
    "What should be done next based on the analysis?\n",
    "\n",
    "Are there areas that need further research?\n",
    "\n",
    "Can we test certain hypotheses in a future project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29078782-d2ab-401c-b156-269f77fa3ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ee80ae8fd4011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fa6d2d5ac72e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
